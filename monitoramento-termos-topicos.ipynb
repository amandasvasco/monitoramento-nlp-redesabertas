{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f476c6-c4be-43a3-a88d-25da5116b0a6",
   "metadata": {},
   "source": [
    "# Monitoramento semanal dos termos e tópicos de conversação (cliente X)\n",
    "\n",
    "Objetivos\n",
    "\n",
    "●\tcompreender como grupos digitais de diferentes posições no espectro político têm discutido questões sobre feminismos, pautas LGBTQI+, direitos sexuais, reprodutivos e gênero;  \n",
    "●\tcompreender, em particular, como se dá o processo de contágio das táticas anti-gênero ou das narrativas progressistas de gênero entre os grupos;  \n",
    "●\tmonitorar mensagens e táticas que possam gerar risco às ativistas e organizações que trabalham com temas de gênero.  \n",
    "\n",
    "---\n",
    "\n",
    "Método\n",
    "  \n",
    "Qual a prevalência dos temas identitários (conforme palavras-chave abaixo) nos grupos?     \n",
    "a. Comparar a frequência das mensagens de política identitária com as mensagens gerais mais compartilhadas no período.  \n",
    "b. Comparar o enquadramento das mensagens sobre políticas identitárias entre os clusters;\n",
    "c. Avaliar se há algum nível de ameaça a ativistas, personalidades ou organizações (a partir dos nomes elencados abaixo)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b21485-e3d7-46a1-90f7-d7c40af52e29",
   "metadata": {},
   "source": [
    "* Instalações e acesso ao Elastich para busca dos index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd94a1e-a9f1-41c7-97b1-9d8269472d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y -c conda-forge hdbscan pygraphviz \n",
    "!pip uninstall -y numpy numba\n",
    "!pip install --no-cache bertopic 'bertopic[visualization]' sklearn plotly ipywidgets xlrd openpyxl elasticsearch==7.12.1 unicode-slugify certifi==2018.8.24 numpy numba\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b2b8b-545e-4a83-9d7f-142a88a08831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import getpass\n",
    "import certifi\n",
    "import urllib3\n",
    "\n",
    "THREADS     = 10 # memórias\n",
    "ES_HOST     = #sigiloso\n",
    "ES_USER     = 'amanda.vasconcellos'\n",
    "ES_PASS     = getpass.getpass()\n",
    "ES_INDEX    = # dados\n",
    "es = Elasticsearch(\n",
    "    [ES_HOST],\n",
    "    http_auth=(ES_USER, ES_PASS),\n",
    "    timeout=60, \n",
    "    max_retries=10, \n",
    "    maxsize=THREADS, \n",
    "    retry_on_timeout=True, \n",
    "    ca_certs=certifi.where(), \n",
    "    verify_certs=False,\n",
    "    ssl_show_warn=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed52b1-524a-4171-9a9e-93ea18b4fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = f\"{(datetime.now() - timedelta(days=6)):%Y-%m-%dT%H:%M:%S.000Z}\" \n",
    "end_date = f'{datetime.now():%Y-%m-%dT%H:%M:%S.000Z}' \n",
    "\n",
    "messages = [] \n",
    "query = {\n",
    "    \"query\":{\n",
    "        \"bool\" : {\n",
    "            \"must\" : [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"timestamp\": {\n",
    "                            \"gte\": start_date, # greater than or equal\n",
    "                            \"lte\": end_date    # less than or equal\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                # {\n",
    "                #     \"term\": {\n",
    "                #         \"type.keyword\": {\n",
    "                #             \"value\": \"extendedText\", # apenas mensagens de texto\n",
    "                #             \"boost\": 1.0\n",
    "                #         }\n",
    "                #     }\n",
    "                # }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    data = es.search(index=ES_INDEX, body=query, scroll='2m', size=1000) \n",
    "    print(\"%s Got %d Hits\" % (ES_INDEX,data['hits']['total']['value']))\n",
    "    scroll_size = len(data['hits']['hits'])\n",
    "    sid = data['_scroll_id']\n",
    "    while scroll_size > 0:\n",
    "        [messages.append(doc['_source']) for doc in data['hits']['hits']] \n",
    "        data = es.scroll(scroll_id=sid, scroll='2m')\n",
    "        sid = data['_scroll_id']\n",
    "        scroll_size = len(data['hits']['hits'])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c58db-f830-4ebc-a9b0-addd1f795475",
   "metadata": {},
   "source": [
    "* Data cleaning:\n",
    "\n",
    "Limpeza das stopwords, tokenize e caracteres para criação de coluna \"clean_content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11fd5e-8144-49da-9308-f81d1788d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk #natural language\n",
    "from nltk.corpus import stopwords # palavras não significantes\n",
    "from nltk.tokenize import word_tokenize # função que divide frase em palavras\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt') # cria listas de palavras, para palavras abreviadas, início de frase\n",
    "\n",
    "#stop_words = stopwords.words('english')\n",
    "stop_words = nltk.corpus.stopwords.words('portuguese')\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    x = x.lower()\n",
    "    x = re.sub(r'#[A-Za-z0-9]*', ' ', x)\n",
    "    x = re.sub(r'https*://.*', ' ', x)\n",
    "    x = re.sub(r'@[A-Za-z0-9]+', ' ', x)\n",
    "    tokens = word_tokenize(x)\n",
    "    x = ' '.join([w for w in tokens if not w.lower() in stop_words])\n",
    "    x = re.sub(r'[%s]' % re.escape('!\"#$%&\\()*+,-;:<=>?@[\\\\]^_`{|}~“…”’'), ' ', x)\n",
    "    x = re.sub(r'\\d+', ' ', x)\n",
    "    x = re.sub(r'\\n+', ' ', x)\n",
    "    x = re.sub(r'\\s{2,}', ' ', x)\n",
    "    return x.strip().split(' ')\n",
    "\n",
    "# msgs = list(filter(lambda x: x['message_type']=='chat',messages))\n",
    "df = pd.DataFrame(messages)\n",
    "df['clean_content'] = df.full_content.apply(clean_text)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b69f75-d7f9-40d6-a7c7-8f4f62b070f5",
   "metadata": {},
   "source": [
    "* Dicionário de termos para monitoramento:\n",
    "\n",
    "Definição de bad_words, termos de gênero, nomes de mulheres da política institucional, ativismo, ciência, jornalismo e organizações; \n",
    "\n",
    "As palavras chave foram selecionadas a partir de estudos prévios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104178b3-b78d-4b6d-8f10-ecfd6fa3264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir objeto filtro para termos de busca\n",
    "\n",
    "term_filters = {\n",
    "    \"bad_words\":{\n",
    "        \"terms\": [\"filho puta\", \"filha puta\", \"filho da puta\",\"filha da puta\",\"filho de uma puta\",\"puta merda\",\"puta pariu\",\"puta que pariu\",\"puta queo pariu\",\"fela da puta\",\"fdp \",\"cuzão\",\"cuzao\",\"merda\",\"canalha\"],\n",
    "        \"title\": \"Palavrões\"\n",
    "    },\n",
    "    \"gender_identity\" : {\n",
    "        \"terms\": [\"Aborto\", \"Abortista\", \"Aborteira\", \"Assassinato de bebês\", \"Bebê não nascido\", \"Criança não nascida\", \"Criança por nascer\", \"Com meus filhos não se meta\", \"Com meus filhos não te metas\", \"Cultura da Morte\", \"Depravadas\", \"Depravada\", \"Depravado\", \"Depravados\", \"Defesa da vida\", \"Defesa da família\", \"Discurso de ódio\", \"Demoníaca\", \"Doutrinação\", \"Doutrina nas escolas\", \"Educação Sexual\", \"Família tradicional\", \"Família natural\", \"Feminismo\", \"Feminista\", \"Feminazi\", \"Gay\", \"Gaysista\", \"Gayzista\", \"Homossexual\", \"Homossexualismo\", \"Homossexualidade\", \"Homem biológico\", \"Homem de bem\", \"Homens de bem\", \"Ideologia de gênero\", \"Infanticídio\", \"Lésbica\", \"Liberdade de expressão\", \"Liberdade Religiosa\", \"Machista\", \"Machismo\", \"Mulher biológica\", \"Mulher de bem\", \"Mulheres de bem\", \"Maníaco Sexual\", \"Mulher indígena\", \"Mulher negra\", \"Mulher preta\", \"Maconheira\", \"Nascituro\", \"Perverso\", \"Perversidade\", \"Patrulhamento ideológico\", \"Pró-vida\", \"Pro vida\", \"Pedofilia\", \"Pedófilo\", \"Pedófila\", \"Politicamente correto\", \"Piranha\", \" Puta \",\" puta\", \"Sapatão\", \"Sexualidade\", \"Satanista\", \"Teleaborto\", \"Tele aborto\", \"Tele-aborto\", \"Transexual\", \"Transgênero\", \"Traveco\", \"Travesti\", \"Vagabunda\", \"Vida desde a concepção\", \"Valor da mulher\"],\n",
    "        \"title\": \"Identidade de Genêro\"\n",
    "    },\n",
    "    \"institucional_policy\" : {\n",
    "        \"terms\":[\"Damares Alves\",\"Damares\",\"Carla Zambelli\",\"Zambelli\",\"Talíria Petrone\",\"Áurea Carolina\",\"Marielle Franco\",\"Marielle\",\"Gleisi Hoffman\",\"Dilma Rousseff\",\"Dilma\",\"Joyce Hasselman\",\"Tabata Amaral\",\"Erika Hilton\",\"Erica Malunguinho\",\"Natália Bonavides\",\"Samia Bonfim\",\"Samia\",\"Monica Benício\",\"Monica Francisco\",\"Isa Penna\",\"Luciana Boiteux\",\"Luiza Erundina\",\"Erundina\",\"Benny Briolly\",\"Carolina Iara\",\"Manuela D’ávila\",\"Erika Kokay\",\"Vivi Reis\",\"Jandira Feghali\",\"Benedita da Silva\",\"Fernanda Melchionna\",\"Simone Tebet\",\"Liana Cirne\",\"Tainá de Paula\",\"Joenia Wapichana\",\"Marília Arraes\",\"Renata Souza\",\"Marina Silva\",\"Maria do Rosário\",\"Rosário\",\"Rosario\",\"Luciana Genro\"],\n",
    "        \"title\": \"Política Institucional\"\n",
    "    },\n",
    "    \"activism\": {\n",
    "        \"terms\": [\"Sonia Correa\",\"Sabrina Fernandes\",\"Sonia Guajajara\",\"Guajajara\",\"Alice Pataxó\",\"Anielle Franco\",\"Luyara Franco\",\"Winnie Bueno\",\"Sandra Lia Bazzo\",\"Camila Mantovani\",\"Simony dos Anjos\",\"Txai Suruí\",\"Vilma Reis\",\"Sueli Carneiro\",\"Andreza Delgado\",\"Jurema Werneck\",\"Lola Aronovich\",\"Marilia Moscou\",\"Lana de Holanda\",\"Amara Moira\",\"Buba Aguiar\",\"Debora Baldin\",\"Carina Vitral\",\"Brenda Safra\",\"Angela Freitas\",\"Paula Guimarães\",\"Paula Viana\",\"Laura Molinari\",\"Leina Peres\",\"Morgani Guzzo\",\" Natalia Veras\",\"Mariana Prandini\",\"Gabriela Rondon\",\"Luciana Brito\",\"Rebeca Mendes\",\"Fernanda Vicari\",\"Luciana Viegas\",\"Joice Berth\",\"Jacira Melo\",\"Lúcia Xavier\",\"Silvia Camurça\",\"Ligia Cardieri\" ],\n",
    "        \"title\": \"Ativistas\"\n",
    "    },\n",
    "    \"science\":{\n",
    "        \"terms\": [\"Debora Diniz\",\"Marcia Tiburi\",\"Emanuelle Goes\",\"Flávia Biroli\",\"Rosana Pinheiro-Machado\",\"Isabela Kalil\",\"Helena Paro\",\"Carla Akotirene\",\"Djamila Ribeiro\",\"Monica de Bolle\",\"Gabriela Priolli\",\"Laura Carvalho\",\"Natalia Pasternak\",\"Nina da Hora\",\"Ethel Maciel\",\"Juliana Borges\",\"Melania Amorim\"],\n",
    "        \"title\": \"Cientistas\"\n",
    "    },\n",
    "    \"journalism\": {\n",
    "        \"terms\": [\"Amanda Audi\",\"Flávia Oliveira\",\"Giulliana Bianconi\",\"Helena Bertho\",\"Fabiana Moraes\",\"Maju Coutinho\",\" Bárbara Libório\",\"Thais Folego\",\"Lola Ferreira\",\"Juliana Dal Piva\",\"Mariana Varella\",\"Eliana Alves Cruz\",\"Andrea Martinelli\",\"Marie Declerq\",\"Andrea Dip\",\"Nayara Felizardo\",\"Miriam Leitão\",\"Vera Magalhães\",\"Cecília Olliveira\",\"Patrícia Campos Melo\",\"Mara Régia\" ],\n",
    "        \"title\" : \"Jornalistas\"\n",
    "    },\n",
    "    \"organizations\": {\n",
    "        \"terms\": [\" Anis \",\" Anis.\",\"Grupo Curumim\",\"Nem Presa Nem Morta\",\"Portal Catarinas\",\" GHS \",\" GHS.\",\"Coletivo Margarida Alves\", \"Margarida Alves\", \"Rede Feminista de Saúde\", \" Criola\",\"Geledes\",\"Coletivo Feminista de Sexualidade e Saúde\",\" Cepia\",\"Católicas pelo direito de decidir\",\"Frente Nacional Pela Legalização do Aborto\",\"FNPLA\",\"Cunhã Feminista\",\"CFEMEA\",\"SOS Corpo\",\"REDEH\",\" CLADEM\",\"Redes da Maré\",\" AMB \",\" AMB.\",\"Articulação de Mulheres Brasileiras\",\" Nossas \",\"Bloco A\",\" SPW \",\"Coalizão Negra por Direitos\",\"Think Olga\",\"Instituto Patrícia Galvão\",\"Gênero e Número\",\"Midia Ninja\",\"Mídia Ninja\"],\n",
    "        \"title\":\"Organizações\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d96af87-db6a-464e-ba4c-abdcb6628108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_terms(x): # gerar coluna de identificação de termos e palavra chave pelo 'clean_content'\n",
    "    x = str(x)\n",
    "\n",
    "    return_keys = [] #criar lista\n",
    "    for key in term_filters.keys():\n",
    "        for value in term_filters[key]['terms']: \n",
    "            if x.lower().find(value.lower()) > -1: # se os valores forem encontrados\n",
    "                return_keys.append( (key,value) )\n",
    "    return return_keys if len(return_keys)>0 else None\n",
    "\n",
    "df['_keys_'] = df.full_content.apply(find_terms) # coluna de lista de tupla [(termo, palavra_chave)]\n",
    "df._keys_.value_counts()\n",
    "\n",
    "# output: [(gender_identity, Gay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2fed9-5291-4e9e-b1b1-c514dbb5145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_keys(row): # gerar colunas únicas de termos\n",
    "    columns = []\n",
    "    if row['_keys_']:\n",
    "        for t in row['_keys_']:\n",
    "            if t[0] in row.keys():\n",
    "                row[t[0]].append(t[1])\n",
    "            else: \n",
    "                row[t[0]] = [t[1]]\n",
    "    return row\n",
    "    \n",
    "        \n",
    "df2 = df.apply(explode_keys,axis=1)\n",
    "df2.columns\n",
    "\n",
    "# output: '_keys_', 'bad_words', 'gender_identity'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e690085-5e4e-425d-9000-f13ee42db520",
   "metadata": {},
   "source": [
    "* Visualização dos termos por tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e3336-f808-4f9a-801d-8ac09ad04219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incidência dos termos de busca por tempo e por flag\n",
    "\n",
    "df2['keys_bool'] = df2._keys_.apply(lambda x: True if type(x) is list else False) # Se houver lista de tupla retornar True\n",
    "df2[['timestamp','keys_bool']].groupby([df2[\"timestamp\"].astype(\"datetime64\").dt.date,'keys_bool'])\\ # agrupar flags por tempo\n",
    "    .count()\\\n",
    "    .rename(columns={'timestamp':'count'})\\\n",
    "    .reset_index()\\\n",
    "    .fillna(0)\\\n",
    "    .sort_values(by='timestamp', ascending=True)\\\n",
    "    .pivot(index='timestamp',columns='keys_bool',values='count')\\\n",
    "    .plot(kind=\"bar\",template='plotly_dark',height=600)\n",
    "\n",
    "# output: histograma da frequência de aparecimento dos termos monitorados no tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca932e7f-00ca-436b-b1a4-e5673661fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequência de aparecimento dos termos\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "# remove primeiro valor que é o array vazio\n",
    "temp=df3._keys_.value_counts()[0:30] # top 30 termos\n",
    "# temp.index[0][0][0] # 'gender_identity'\n",
    "\n",
    "# constroi um dicionário somando a frequencia dos termos de forma individual\n",
    "graph = {}\n",
    "for i,v in enumerate(temp):\n",
    "    for k in temp.index[i]:\n",
    "        key = f'{k[0]}__{k[1]}'\n",
    "        if graph.get(key):\n",
    "            graph[key] += v\n",
    "        else:\n",
    "            graph[key] = v\n",
    "\n",
    "#transforma o dicionário em tuplas e as tuplas em um DataFrame\n",
    "df01_3 = pd.DataFrame(graph.items(),columns=['termo','frequencia']) \n",
    "\n",
    "df01_3.sort_values('frequencia',ascending=False).plot(x='termo',y='frequencia',kind='bar',template='plotly_dark',height=600).show()\n",
    "\n",
    "# output: plota o grafico de barras de termos encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b45c8e-7b3d-4dab-b3b4-b99d30331dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotar a frequeência dos termos e palavras chave separadamente ao longo do tempo\n",
    "\n",
    "df2['identidade'] = df2[pd.isna(df2.bad_words)].gender_identity.fillna('sem_ocorrencia').astype(str) # identidade = termos de genero sem as bad_words\n",
    "df2['identidade'] = df2.identidade.apply(lambda x: str(x)[:30]) \n",
    "df2[df2['identidade']!='sem_ocorrencia'][['timestamp','identidade']]\\\n",
    "    .groupby(\n",
    "        [ \n",
    "            df2[\"timestamp\"].astype(\"datetime64\").dt.date,\n",
    "            'identidade'\n",
    "        ]\n",
    "    )\\\n",
    "    .count()\\\n",
    "    .rename(columns={'timestamp':'count'})\\\n",
    "    .reset_index()\\\n",
    "    .sort_values(by='timestamp', ascending=True)\\\n",
    "    .pivot(index='timestamp',columns='identidade',values='count')\\\n",
    "    .plot(kind=\"bar\",template='plotly_dark',height=600)\n",
    "\n",
    "# output: gráfico de barras empilhadas com as principais palavras chave por dia (frequência absoluta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58274a3a-0dd3-49e8-acbc-d5e75deef856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# métrica percentual\n",
    "\n",
    "df2['identidade_bool'] = df2.gender_identity.apply(lambda x: True if type(x) is list else False)\n",
    "df01 = df2[pd.isna(df2.bad_words)][['timestamp','identidade_bool']]\\\n",
    "    .groupby([df2[\"timestamp\"].astype(\"datetime64\").dt.date,'identidade_bool'])\\\n",
    "    .count()\\\n",
    "    .rename(columns={'timestamp':'count'})\\\n",
    "    .reset_index()\\\n",
    "    .fillna(0)\\\n",
    "    .sort_values(by='timestamp', ascending=True)\\\n",
    "    .pivot(index='timestamp',columns='identidade_bool',values='count')\n",
    "\n",
    "df01.columns = ['False','True']\n",
    "df01['total'] = df01[['False','True']].fillna(0).apply(lambda row: row['True'] + row['False'],axis=1)\n",
    "\n",
    "df01['sem_ocorrencia'] = df01.apply(lambda row: row['False']/row['total']*100,axis=1)\n",
    "df01['com_ocorrencia'] = df01.apply(lambda row: row['True']/row['total']*100,axis=1)\n",
    "\n",
    "df01[['sem_ocorrencia','com_ocorrencia']].plot(kind=\"bar\",template='plotly_dark',height=400)\n",
    "\n",
    "# output: gráfico de barras com colunas percentuais das frequências identificadas por flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd0b128-97b5-4dab-950e-c1c1c5f17bfd",
   "metadata": {},
   "source": [
    "* Gerando dataset para a equipe de análise de dados\n",
    "\n",
    "Objetivo: fornecer para a equipe alguns exemplos de ocorrências que se adequam ao modelo metodológico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb381f-4a8f-47b6-9434-a54a42a3d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando filtro para identificação de mensagens com termos de gênero:\n",
    "\n",
    "filtro_gender = df2.loc[(df2.identidade_bool != False)] # onde a flag para gênero é True\n",
    "\n",
    "filtro_gender.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3a398-2441-404a-a0b6-430b4b980879",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocorrencias_gender = filtro_gender.groupby([filtro_gender.content, filtro_gender.identidade])\\ # agregando conteúdo da mensagem True\n",
    "[['content','group']]\\\n",
    "    .agg({\n",
    "        'content':['count'], # gerando frequencia de aparecimento da mesma mensagem\n",
    "         'group':['count'] # frequência de repetição\n",
    "        \n",
    "    })\\\n",
    "    .reset_index()\n",
    "\n",
    "ocorrencias_gender.columns = ['content', 'gender_key','content_count', 'group_count']\n",
    "ocorrencias_gender.sort_values(by='content_count', ascending=False)\n",
    "\n",
    "# output: dataset organizado em 4 colunas \n",
    "#(conteúdo integral da mensagem, chave de gênero identificada, frequência absoluta de aparecimento da mensagem e frequência de grupos enviados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc03ad93-60fd-45da-b54c-3d49773a8d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar csv \n",
    "\n",
    "ocorrencias_gender.to_csv('ocorrencias_gender_agrupadas.csv', index=False)\n",
    "\n",
    "#obs: podem ser criados filtros para qualquer tipo de termo monitorado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9296de2-68ee-4cf7-b8a9-e934e406d26d",
   "metadata": {},
   "source": [
    "* Identificação de tópicos de conversação\n",
    "\n",
    "Utilizando o BERTopic (modelagem de tópicos por classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae23001f-fe19-40bc-a4fc-d88a0280ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelagem de tópicos por classe\n",
    "\n",
    "from bertopic import BERTopic #modelagem\n",
    "import os #sistema operacional\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'true'\n",
    "\n",
    "topic_model = BERTopic(language=\"portuguese\", calculate_probabilities=True, verbose=True, low_memory=False) #calculando probabilidade\n",
    "\n",
    "chat_topics = []\n",
    "docs = []\n",
    "timestamps = []\n",
    "\n",
    "for chat_id in df.chat_id.value_counts()[df.chat_id.value_counts() > 10].index.values: # para grupos com mais de 10 partifcipantes na conversa\n",
    "    [docs.append(doc) for doc in df[df.chat_id == chat_id]['clean_content'].values] # utilizando a mesma coluna de mensagens 'clean_content'\n",
    "    [timestamps.append(doc) for doc in df[df.chat_id == chat_id]['timestamp'].values] # append timestamp\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs) # tranformandoo modelo pelos dados (docs)\n",
    "freq = topic_model.get_topic_info() # Observar as frequências dos tópicos mais comuns e dos menos frequentes (-1) que serão provavlemente ignorados\n",
    "\n",
    "# output: dataset contendo os tópicos agrupados por BERTopic e as respectivas frequências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06065bc9-4a50-49d4-9f01-cfe45d35919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Após treinar o modelo, gerar as visualizações para melhor entendimento dos tópicos gerados\n",
    "\n",
    "topic_model.visualize_topics()\n",
    "\n",
    "#output: gráfico de visualização dos tópicos, seus tamanho ao longo dos eixos e proximidade semântica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20902bad-9840-4f31-8c91-a6413f4e55a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui é feita a hierarquização dos tópicos (n foi definido através e clusteriação prévia)\n",
    "\n",
    "topic_model.visualize_hierarchy(top_n_topics=20)\n",
    "\n",
    "#output: relação hierárquica entre os tópicos de conversação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd0b5f-655a-4ba6-84d1-696536a19ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar termos por tópicos\n",
    "\n",
    "topic_model.visualize_barchart(top_n_topics=10)\n",
    "\n",
    "#output: Gráficos de barra com as frequências de termos por tópicos (Aqui comparamos os \"term_filters\" gerados na primeira parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1989cac-958d-42b0-bf9a-aa2c7940212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz de similaridade\n",
    "\n",
    "topic_model.visualize_heatmap(n_clusters=20, width=1000, height=1000)\n",
    "\n",
    "# output: semelhança de cosseno pelos embeddings (avaliar possíveis tópicos correlacionados e o repercussão dos tópicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64930449-2f05-4734-aa2e-38ae6019f880",
   "metadata": {},
   "source": [
    "* Clusterizando os tipos de senders (usuários) pelo conteúdo das mensagens (content)\n",
    "\n",
    "Utilizando Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00855fd-b4a4-4b95-b4bb-5890869a7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering senders by content\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('portuguese') # data cleaning\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "df['content_len'] = df.content.astype(str).apply(lambda x: len(x.strip())) # valores de content\n",
    "cdf = df[(~pd.isna(df['content'])) & (df['content_len']>1) ].drop_duplicates(subset=['content'],keep='first') # documentos \n",
    "\n",
    "documents = cdf.clean_content.apply(lambda x: ' '.join(x) if x[0] != None else x) \n",
    "# documents\n",
    "X = vectorizer.fit_transform(documents) \n",
    "\n",
    "cost = []\n",
    "K = range(1,25)\n",
    "for num_clusters in list(K):\n",
    "    print(f'Calculating with {num_clusters}',end='\\r')\n",
    "    km = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=1000, n_init=5, verbose=0)\n",
    "    km.fit_predict(X)\n",
    "    cost.append(km.inertia_)\n",
    "    \n",
    "plt.plot(K, cost, 'bx-')\n",
    "plt.xlabel('No. of clusters')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()\n",
    "\n",
    "# output: gráfico dos valores de K (melohores números de clusters pelos tópicos), Ex: 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62613d6e-0acd-469c-a7a6-f3e395c09fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 23 # valor de k \n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=1000, n_init=1)\n",
    "model.fit(X) \n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind])\n",
    "        \n",
    "# output: top terms por cluster. \n",
    "# Ex: cluster 1: mulheres, luta, brasil, deus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39efdeb-f9b3-4d85-a6b3-cb21f6d7d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer predictions to dataset\n",
    "\n",
    "def content_clustering(x):\n",
    "    Y = vectorizer.transform(x)\n",
    "    prediction = model.predict(Y)\n",
    "    return prediction[0]\n",
    "\n",
    "ccs = df[(~pd.isna(df['content'])) & (df['content_len']>1)].drop_duplicates(subset=['content'],keep='first')[['content','clean_content']].values\n",
    "for i,item in enumerate(ccs):\n",
    "    print(f'{i}/{len(ccs)}',end='\\r')\n",
    "    filtro = (df02.content == item[0])\n",
    "    df02.content_cluster.value_counts(dropna=False)\n",
    "    \n",
    "# output: dataset original com mensagens clusterizadas por tópicos em \"content_cluster\"\n",
    "# Ex: \"content\": Mulheres no Brasil representam o maior número de trabalhadores informais; \"content_cluster\": cluster 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
